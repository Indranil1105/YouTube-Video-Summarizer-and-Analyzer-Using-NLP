{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3997d31b-f12c-4839-b738-0d6d0e3b36fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Desktop\\YVSN\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from transformers import pipeline\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8599399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that necessary NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02c862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize text\n",
    "def summarize_text(text, max_length=50000):\n",
    "    summarization_pipeline = pipeline(\"summarization\")\n",
    "    summary = summarization_pipeline(text, max_length=max_length, min_length=50, do_sample=False)\n",
    "    return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c38dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords\n",
    "def extract_keywords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum()]\n",
    "    keywords = [word for word in words if word not in stop_words and len(word) > 1]\n",
    "\n",
    "    counter = CountVectorizer().fit_transform([' '.join(keywords)])\n",
    "    vocabulary = CountVectorizer().fit([' '.join(keywords)]).vocabulary_\n",
    "    top_keywords = sorted(vocabulary, key=vocabulary.get, reverse=True)[:5]\n",
    "\n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60183631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform topic modeling (LDA)\n",
    "def topic_modeling(text):\n",
    "    vectorizer = CountVectorizer(max_df=2, min_df=0.95, stop_words='english')\n",
    "    tf = vectorizer.fit_transform([text])\n",
    "    lda_model = LatentDirichletAllocation(n_components=5, max_iter=5, learning_method='online', random_state=42)\n",
    "    lda_model.fit(tf)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        topics.append([feature_names[i] for i in topic.argsort()[:-6:-1]])\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3378d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract YouTube video ID from URL\n",
    "def extract_video_id(url):\n",
    "    video_id = None\n",
    "    patterns = [\n",
    "        r'v=([^&]+)',  # Pattern for URLs with 'v=' parameter\n",
    "        r'youtu.be/([^?]+)',  # Pattern for shortened URLs\n",
    "        r'youtube.com/embed/([^?]+)'  # Pattern for embed URLs\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            video_id = match.group(1)\n",
    "            break\n",
    "    return video_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09dea0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 16:27:51.885 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.089 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Dell\\Desktop\\YVSN\\venv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-27 16:27:59.090 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.094 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.105 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.111 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-27 16:27:59.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.151 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.153 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.156 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-27 16:27:59.158 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Main Streamlit app\n",
    "def main():\n",
    "    st.title(\"YouTube Video Summarizer\")\n",
    "\n",
    "    # User input for YouTube video URL\n",
    "    video_url = st.text_input(\"Enter YouTube Video URL:\", \"\")\n",
    "\n",
    "    # User customization options\n",
    "    max_summary_length = st.slider(\"Max Summary Length:\", 1000, 20000, 50000)\n",
    "\n",
    "    if st.button(\"Summarize\"):\n",
    "        try:\n",
    "            # Extract video ID from URL\n",
    "            video_id = extract_video_id(video_url)\n",
    "            if not video_id:\n",
    "                st.error(\"Invalid YouTube URL. Please enter a valid URL.\")\n",
    "                return\n",
    "\n",
    "            # Get transcript of the video\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            if not transcript:\n",
    "                st.error(\"Transcript not available for this video.\")\n",
    "                return\n",
    "\n",
    "            video_text = ' '.join([line['text'] for line in transcript])\n",
    "\n",
    "            # Summarize the transcript\n",
    "            summary = summarize_text(video_text, max_length=max_summary_length)\n",
    "\n",
    "            # Extract keywords from the transcript\n",
    "            keywords = extract_keywords(video_text)\n",
    "\n",
    "            # Perform topic modeling\n",
    "            topics = topic_modeling(video_text)\n",
    "\n",
    "            # Perform sentiment analysis\n",
    "            sentiment = TextBlob(video_text).sentiment\n",
    "\n",
    "            # Display summarized text, keywords, topics, and sentiment\n",
    "            st.subheader(\"Video Summary:\")\n",
    "            st.write(summary)\n",
    "\n",
    "            st.subheader(\"Keywords:\")\n",
    "            st.write(keywords)\n",
    "\n",
    "            st.subheader(\"Topics:\")\n",
    "            for idx, topic in enumerate(topics):\n",
    "                st.write(f\"Topic {idx+1}: {', '.join(topic)}\")\n",
    "\n",
    "            st.subheader(\"Sentiment Analysis:\")\n",
    "            st.write(f\"Polarity: {sentiment.polarity}\")\n",
    "            st.write(f\"Subjectivity: {sentiment.subjectivity}\")\n",
    "\n",
    "        except TranscriptsDisabled:\n",
    "            st.error(\"Transcripts are disabled for this video.\")\n",
    "        except NoTranscriptFound:\n",
    "            st.error(\"No transcript found for this video.\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
